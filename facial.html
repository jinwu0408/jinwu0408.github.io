<!DOCTYPE html>
<html>

<head>
  <title>Facial Recognition</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="shortcut icon" type="image/png" sizes="48x48" href="img/logo.png">
  <link href='https://fonts.googleapis.com/css?family=Varela+Round' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="css/Facial_rec.css">
</head>

<body>
  <div class="banner facial_banner">
    <div class="banner_inner">
      <h1 class="shadow">Facial Recognition</h1>
      <a href="#content"><img class="arrow" src="img/arrow.svg" alt="Down arrow"></a>
    </div>
  </div>
  <div class="context">
    <div class="primary-content indent" id="content">
      <div class="hori_bar_blue">
        <!--introduction-->
        <h1 class="title">What is Facial Recognition?</h1>
        <p>
          A facial recognition system is a technology capable of identifying or verifying a
          person from a digital image. We used <a href="#opencv">OpenCV for image processing,
            RPi to capture real time pictures, <a href="Tensorflow">Tensorflow(Keras)</a> to train
            and <a href="AWS">AWS</a> for hosting services.
        </p>
      </div>
      <!--End introduction-->
      <div class="hori_bar_blue clearfix">
        <h1>Project Break Down</h1>
        <div class="right1">
          <h2>Phase 1:</h2>
          <ul>
            <li>Image Processing with CV2</li>
            <li>Convolutional Neural Network(CNN)</li>
          </ul>
        </div>
        <div class="right1">
          <h2>Phase 2:</h2>
          <ul>
            <li>Set up Raspberry Pi</li>
            <li>Real-time Face Detection</li>
            <li>Data Collection</li>
          </ul>
        </div>
        <div class="right1">
          <h2>Phase 3:</h2>
          <ul>
            <li>Fine Tuning CNN</li>
            <li>Connect an IoT Module</li>
          </ul>
        </div>
      </div>

      <div class="hori_bar_blue clearfix">
        <!--Phase 1 -->
        <h1>Phase 1:</h1>
        <div class="left">
          <h2>Image Processing with CV2</h2>
          <p>Get familiar with <b>OpenCV</b> by doing some simple image processing
            techniques such as "resized", "recolored", and "drawn onto an image".
            The goal is to process the orignal Geisel library with the following
            modification:
          </p>
          <ul>
            <li><b>Read</b> a color image (“geisel.jpg”) as grayscale</li>
            <li><b>Resize</b> it to half of its original dimensions</li>
            <li><b>Draw </b>a 100x100 white box at the center of the image</li>
            <li><b>Save </b>the new image to a local directory.</li>
          </ul>
        </div>
        <div class="right">
          <div class="image">
            <img src="img/geisel.jpg" alt="Geisel_Before_processed">
            <figcaption>Fig.1 Image before processing.</figcaption>
          </div>
          <div class="image">
            <img src="img/geisel_processed.jpg" alt="Geisel_processed">
            <figcaption>Fig.2 Image after processing.</figcaption>
          </div>
        </div>
        <h2>Convolutional Neural Network(CNN)</h2>
        <p>Get Familiar with CNN and Keras by writing a <b>modified LeNet</b> in Keras.</p>
        <div class="image">
          <img src="img/LeNet.png" alt="LeNet">
          <figcaption>Fig.3 The architecture of the modified LeNet.</figcaption>
        </div>
        <p><b>Network Architecture:</b></p>
        <ul>
          <li>Input dimensions: 32x32x1
          <li>C1: <b>Convolutional layer</b>, output: 6 layers of 28x28 feature maps, filter size: 5x5, strides: 1 both
            horizontally and vertically, activation function: sigmoid</li>
          <li>S2: <b>Max pooling layer</b>, output: 6 layers of 14x14 feature maps, pooling size: 2x2, strides: 2 both
            horizontally and vertically</li>
          <li>C3: <b>Convolutional layer</b>, output: 16 layers of 10x10 feature maps, filter size: 5x5, strides: 1 both
            horizontally and vertically, activation function: sigmoid</li>
          <li>S4: <b>Max pooling layer</b>, output: 16 layers of 5x5 feature maps, pooling size: 2x2, strides: 2 both
            horizontally and vertically</li>
          <li>C5: <b>Convolutional layer</b>, output: 120 layers of 1x1 feature maps, filter size: 5x5, activation function:
            sigmoid</li>
          <li>F6: <b>Fully connected layer</b>, output 84­dimensional vector, activation function: tanh</li>
          <li>F7: <b>Fully connected layer</b>, output 10­dimensional vector, activation function: softmax</li>
        </ul>
      </div>
      <!--End Phase 1 -->

      <div class="hori_bar_blue">
        <!--Phase 2 -->
        <h1>Phase 2:</h1>
        <h2>Set up Raspberry Pi</h2>
        <p>Set up the environment of the Raspberry Pi, including necessary
          libraries, such as OpenCV and Tensorflow. Then, add the Raspberry Pi
          camera module.</p>
        <div class="image">
          <img src="img/rapsberry.jpg" alt="raspberry">
          <figcaption>Fig.3 The architecture of the modified LeNet.</figcaption>
        </div>
        <h2>Real-time Face Detection</h2>
        <p>Apply the face detection method in OpenCV to detect faces in
          real­time videos, taken by Raspberry PI camera. OpenCV face detection is
          based on the Viola­Jones Haar Cascade face detection algorithm. Then,
          we need tograyscale video with 120x160 (height x width) dimensions,
          with a white box on faces. </p>
        <h2>Data Collection</h2>
        <p>Next step is to prepare some good data sets, which involve 3 steps. </p>
        <ul>
          <li>Find public face datasets onling</li>
          <li>Prepare personal face data.</li>
          <li>Sort data into 3 set, training, validation, and test.</li>
        </ul>
        <p>We found public datasets on <a target="_blank" href="http://www.face-rec.org/databases/">
            http://www.face-rec.org/databases</a>, which involve 17 differnet
          classes, labeled 00~16 respectively.</p>
        <p>Then, we wrote a python program with Raspberry Pi camera that automatically takes
          every seconds. Then the photo would be turn into greyscale, resized, and saved.
          All we need to do after is let the camera detect our face, collecting our face data.
          when taking pictures, we want a full range of angle and emotion, so that
          the model can be well-trained.</p>
        <p>Last, we wrote another program called "Organizer" that shaffle and sort
          the data into 3 subsets, Traing, Validation, Test with 70%, 20%,
          10% respectively.</p>
        <div class="clearfix">
          <div class="left image">
            <img src="img/facial_data.jpg" alt="data1">
            <figcaption>Fig.4 The facial data found on http://www.face-rec.org/databases</figcaption>
          </div>
          <div class="right image">
            <img src="img/facial_data_1.png" alt="data1">
            <figcaption>Fig.5 Sample of personal data with emotions.</figcaption>
          </div>
        </div>
      </div>
      <!--End Phase 2 -->

      <div>
        <!--Phase 3 -->
        <h1>Phase 3:</h1>
        <h2>Fine Tuning CNN</h2>
        <p>WeWhen training a network, we have to option, training from scratch and fine tuning from a trained model.
          Training from scratch will take a lot
          longer than fine tuning. To finetune with our own data, we will need the weights from a pretrained model. In
          this project, we will use a network called VGG16. You can find an example here: https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3
        </p>
        <p>To speed up the trainning process, which takes a long time. We used
          AWS(Amazon Web Service), which has the computation power to make the
          process quick. After the model is trained well, we save the weight.
        </p>
        <p>Last, to make sure our model and weights are ready to go, we run the
          test set. The accuracy ends about 97%, which means the model is well-trained.</p>
        <h2>Connect an IoT Module</h2>
        <div class="clearfix">
          <div class="image right">
            <img src="img/facial_2.jpg" alt="facial">
            <figcaption>Fig.5 The correct labeled data picture of JIN!</figcaption>
          </div>
          <p class="left">Last piece of this projecti is connect everything together. We need
            to host a server with Flask, Python library for web services that
            process the image that is taken by Rapsberry Pi Camera. After the Camera
            detect the face, it will ask if the photo is okay. If it is, then the image
            would be sent to the AWS server.py, which would return with the name of the
            face. Beautifully, we would have a correct identity on our pretty face.
          </p>
        </div>
      </div>
      <!--End Phase 3 -->

    </div><!-- End .primary-content -->
  </div>

  <footer>
    <ul>
      <li><a href="https://twitter.com/jinwu0408" target=_blank class="social twitter">Twitter</a></li>
      <li><a href="https://www.linkedin.com/in/jin-wu/" target=_blank class="social linkedin">LinkedIn</a></li>
      <li><a href="https://github.com/jinwu0408" target=_blank class="social github">Github</a></li>
      <li><a href="mailto:jinwu0408@gmail.com" target=_blank class="social google">Email</a></li>
      <li><a href="https://www.instagram.com/jin_wu/" target=_blank class="social instagram">Instagram</a></li>
    </ul>
    <p class="copyright">Copyright 2019, Jin Wu</p>
  </footer>
</body>

</html>
